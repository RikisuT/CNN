{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "print(num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the dataset directory\n",
    "data_dir = \"/home/rikisu/NNDL/CNN/cell_images\"\n",
    "\n",
    "# Set the number of training epochs (you can increase this later for better accuracy)\n",
    "epochs = 2\n",
    "\n",
    "# Automatically set the number of worker processes for data loading\n",
    "# based on the number of available CPU cores\n",
    "num_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "class MalariaCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MalariaCNN, self).__init__()\n",
    "        \n",
    "        #---------- CONVOLUTIONAL LAYERS ----------#\n",
    "        # First convolutional block\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)  # Input: 3 channels (RGB), Output: 32 feature maps\n",
    "        self.relu1 = nn.ReLU()  # Activation function\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Reduces spatial dimensions by half\n",
    "        \n",
    "        # Second convolutional block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)  # Input: 32 channels, Output: 64 feature maps\n",
    "        self.relu2 = nn.ReLU()  # Activation function\n",
    "        # MaxPool reused from above\n",
    "        \n",
    "        # Third convolutional block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)  # Input: 64 channels, Output: 128 feature maps\n",
    "        self.relu3 = nn.ReLU()  # Activation function\n",
    "        # MaxPool reused from above\n",
    "        \n",
    "        #---------- FULLY CONNECTED LAYERS ----------#\n",
    "        # First fully connected layer\n",
    "        # After 3 max pooling operations (each reducing dimensions by 2), the 200x200 image becomes 25x25\n",
    "        # With 128 feature maps, we get 128*25*25 input features\n",
    "        self.fc1 = nn.Linear(128 * 25 * 25, 128)  # Dense layer to reduce dimensionality\n",
    "        self.relu4 = nn.ReLU()  # Activation function\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(128, 2)  # Binary classification (parasitized vs uninfected)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First convolutional block with pooling\n",
    "        x = self.conv1(x)        # Apply convolution\n",
    "        x = self.relu1(x)        # Apply activation\n",
    "        x = self.pool(x)         # Apply max pooling (200x200 -> 100x100)\n",
    "        \n",
    "        # Second convolutional block with pooling\n",
    "        x = self.conv2(x)        # Apply convolution\n",
    "        x = self.relu2(x)        # Apply activation\n",
    "        x = self.pool(x)         # Apply max pooling (100x100 -> 50x50)\n",
    "        \n",
    "        # Third convolutional block with pooling\n",
    "        x = self.conv3(x)        # Apply convolution\n",
    "        x = self.relu3(x)        # Apply activation\n",
    "        x = self.pool(x)         # Apply max pooling (50x50 -> 25x25)\n",
    "        \n",
    "        # Flatten the tensor for the fully connected layers\n",
    "        x = x.view(x.size(0), -1)  # Reshape to [batch_size, 128*25*25]\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.fc1(x)          # First dense layer\n",
    "        x = self.relu4(x)        # Apply activation\n",
    "        x = self.fc2(x)          # Output layer (logits)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- DATA PREPARATION ----------#\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),  # Resize all images to 200x200\n",
    "    transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize pixel values\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)  # Expects data in folders named by class\n",
    "train_size = int(0.8 * len(dataset))  # 80% training data\n",
    "test_size = len(dataset) - train_size  # 20% testing data\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- MODEL SETUP ----------#\n",
    "# Initialize model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "model = MalariaCNN().to(device)  # Move model to GPU if available\n",
    "criterion = nn.CrossEntropyLoss()  # Loss function for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- TRAINING LOOP ----------#\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Enable mixed precision training\n",
    "scaler = torch.amp.GradScaler()  # Fixed: removed 'cuda' parameter\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "\n",
    "    for images, labels in progress_bar:\n",
    "        # Move data to device\n",
    "        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        with torch.amp.autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):  # Mixed precision\n",
    "            outputs = model(images)  # Get model predictions\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "\n",
    "        # Backward pass with gradient scaling for mixed precision\n",
    "        scaler.scale(loss).backward()  # Compute gradients\n",
    "        scaler.step(optimizer)  # Update weights\n",
    "        scaler.update()  # Update scaler\n",
    "\n",
    "        # Track loss\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=running_loss / (progress_bar.n + 1))\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    #---------- EVALUATION ----------#\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            outputs = model(images)  # Get model predictions\n",
    "            _, predicted = torch.max(outputs, 1)  # Get class with highest probability\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()  # Count correct predictions\n",
    "\n",
    "    # Calculate and store accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    test_accuracies.append(accuracy)\n",
    "    print(f\"Test Accuracy after epoch {epoch+1}: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------- VISUALIZATION ----------#\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs + 1), train_losses, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Training Loss over Epochs\")\n",
    "\n",
    "# Plot test accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs + 1), test_accuracies, marker='o', linestyle='-', color='r')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Accuracy (%)\")\n",
    "plt.title(\"Test Accuracy over Epochs\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
